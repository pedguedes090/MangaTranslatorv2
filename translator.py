#!/usr/bin/env python3
"""
Enhanced Manga Translator Module
===============================

A comprehensive translation system for manga/comic text with context-aware AI translation.

üÜï NEW FEATURES:
- Context metadata support for smart pronoun/honorific selection
- Locked output format (translation only - no explanations)  
- Language-specific rules for JA/ZH/KO comics
- SFX and thought bubble specialized handling
- Bubble fitting with character limits
- Line preservation for multi-bubble text

Features:
- Multiple translation backends (Google, Gemini AI, HuggingFace, Sogou, Bing)
- Context-aware translation with relationship/formality/gender metadata
- Language-specific prompts (Japanese manga, Chinese manhua, Korean manhwa)
- Clean output guarantee (no AI explanations or multiple options)
- Automatic language detection
- Error handling and fallbacks

Author: MangaTranslator Team  
License: MIT
Version: 2.0 (Enhanced Prompt System)
"""

# Translation libraries
from deep_translator import GoogleTranslator
from transformers import pipeline
import translators as ts

# Standard library imports
import requests
import random
import time
import os
import json
from typing import List, Dict, Optional, Tuple

# Import API Key Manager
from api_key_manager import ApiKeyManager


class MangaTranslator:
    """
    Multi-service translator optimized for manga/comic text translation with context awareness.
    
    üÜï NEW: Context metadata support for intelligent translation:
    - Smart pronoun/honorific selection based on relationship and formality
    - Gender-aware translation for natural Vietnamese output  
    - Bubble fitting with character limits
    - SFX and internal thought specialized handling
    - Clean output guarantee (no AI explanations)
    """
    
    def __init__(self, gemini_api_key=None):
        """
        Initialize the translator with optional Gemini API key and API Key Manager
        
        Args:
            gemini_api_key (str, optional): Gemini API key for AI translation
        """
        self.target = "vi"  # Target language: Vietnamese
        
        # Supported source languages mapping
        self.supported_languages = {
            "auto": "T·ª± ƒë·ªông nh·∫≠n di·ªán",
            "ja": "Ti·∫øng Nh·∫≠t (Manga)",
            "zh": "Ti·∫øng Trung (Manhua)", 
            "ko": "Ti·∫øng H√†n (Manhwa)",
            "en": "Ti·∫øng Anh"
        }
        
        # Initialize API Key Manager
        try:
            self.api_key_manager = ApiKeyManager()
            print("‚úÖ API Key Manager initialized")
        except Exception as e:
            print(f"‚ö†Ô∏è API Key Manager failed to initialize: {e}")
            self.api_key_manager = None
        
        # Initialize Gemini API key (fallback to single key mode)
        if not gemini_api_key:
            gemini_api_key = os.getenv("GEMINI_API_KEY")
        
        if gemini_api_key and gemini_api_key.strip():
            self.gemini_api_key = gemini_api_key.strip()
            print(f"‚úÖ Fallback Gemini API key configured: {self.gemini_api_key[:10]}...")
        else:
            self.gemini_api_key = None
        
        # Translation methods mapping
        self.translators = {
            "google": self._translate_with_google,
            "hf": self._translate_with_hf,
            "sogou": self._translate_with_sogou,
            "bing": self._translate_with_bing,
            "gemini": self._translate_with_gemini
        }

    def translate(self, text, method="google", source_lang="auto", context=None, custom_prompt=None):
        """
        Translate text to Vietnamese using the specified method with context support
        
        Args:
            text (str): Text to translate
            method (str): Translation method ("google", "gemini", "hf", "sogou", "bing")
            source_lang (str): Source language code - "auto", "ja", "zh", "ko", "en"
            context (dict, optional): Context metadata for better translation:
                - gender: 'male'/'female'/'neutral' (default: 'neutral')
                - relationship: 'friend'/'senior'/'junior'/'family'/'stranger' (default: 'neutral') 
                - formality: 'casual'/'polite'/'formal' (default: 'casual')
                - bubble_limit: int (character limit for bubble fitting)
                - is_thought: bool (internal monologue/thought bubble)
                - is_sfx: bool (sound effect)
                - scene_context: str (brief scene description)
            custom_prompt (str, optional): Custom translation style prompt to override defaults
            
        Returns:
            str: Translated text in Vietnamese
        """
        
        # Ki·ªÉm tra xem c√≥ API key Gemini kh√¥ng (t·ª´ manager ho·∫∑c fallback)
        has_gemini_key = False
        if method == "gemini":
            # Ki·ªÉm tra API Key Manager tr∆∞·ªõc
            if self.api_key_manager:
                try:
                    manager_key = self.api_key_manager.get_api_key('gemini')
                    has_gemini_key = bool(manager_key)
                except:
                    has_gemini_key = False
            
            # N·∫øu kh√¥ng c√≥ t·ª´ manager, ki·ªÉm tra fallback key
            if not has_gemini_key:
                has_gemini_key = bool(self.gemini_api_key)
        
        if method == "gemini" and not has_gemini_key:
            print("‚ö†Ô∏è Gemini API not available, falling back to Google Translate")
            method = "google"
        elif method == "gemini" and has_gemini_key:
            print("ü§ñ Using Gemini 2.0 Flash for context-aware translation")
            
        translator_func = self.translators.get(method)

        if translator_func:
            if method == "gemini":
                return translator_func(self._preprocess_text(text), source_lang, context, custom_prompt)
            else:
                return translator_func(self._preprocess_text(text), source_lang)
        else:
            raise ValueError("Invalid translation method.")
            
    def _translate_with_google(self, text, source_lang="auto"):
        self._delay()
        
        # Map our language codes to Google's codes
        google_lang = source_lang
        if source_lang == "zh":
            google_lang = "zh-cn"
        
        translator = GoogleTranslator(source=google_lang, target=self.target)
        translated_text = translator.translate(text)
        return translated_text if translated_text is not None else text

    def _translate_with_hf(self, text, source_lang="auto"):
        # HF pipeline ch·ªâ h·ªó tr·ª£ Japanese to English, fallback to Google
        print("‚ö†Ô∏è Helsinki-NLP ch·ªâ h·ªó tr·ª£ Nh·∫≠t ‚Üí Anh, chuy·ªÉn sang Google Translate")
        return self._translate_with_google(text, source_lang)

    def _translate_with_sogou(self, text, source_lang="auto"):
        self._delay()
        
        # Map to sogou language codes
        sogou_lang = "auto" if source_lang == "auto" else source_lang
        
        translated_text = ts.translate_text(text, translator="sogou",
                                            from_language=sogou_lang,
                                            to_language=self.target)
        return translated_text if translated_text is not None else text

    def _translate_with_bing(self, text, source_lang="auto"):
        self._delay()
        
        # Map to bing language codes  
        bing_lang = "auto" if source_lang == "auto" else source_lang
        
        translated_text = ts.translate_text(text, translator="bing",
                                            from_language=bing_lang, 
                                            to_language=self.target)
        return translated_text if translated_text is not None else text

    def _translate_with_gemini(self, text, source_lang="auto", context=None, custom_prompt=None):
        """
        Translate using Google Gemini 2.0 Flash with context metadata support.
        
        Args:
            text (str): Text to translate
            source_lang (str): Source language
            context (dict, optional): Context metadata with keys:
                - gender: 'male'/'female'/'neutral'
                - relationship: 'friend'/'senior'/'junior'/'family'/'stranger'
                - formality: 'casual'/'polite'/'formal'
                - bubble_limit: int (character limit)
                - is_thought: bool (internal monologue)
                - is_sfx: bool (sound effect)
                - scene_context: str (brief scene description)
        """
        # L·∫•y API key t·ª´ manager ho·∫∑c fallback
        api_key = None
        
        # Th·ª≠ l·∫•y t·ª´ API Key Manager tr∆∞·ªõc
        if self.api_key_manager:
            try:
                api_key = self.api_key_manager.get_api_key('gemini')
            except Exception as e:
                print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y API key t·ª´ manager: {e}")
        
        # N·∫øu kh√¥ng c√≥ t·ª´ manager, d√πng fallback key
        if not api_key:
            api_key = self.gemini_api_key
        
        if not api_key:
            raise ValueError("Gemini API key not configured")
        
        # Clean input text
        text = text.strip() if text else ""
        if not text:
            print("‚ö†Ô∏è Empty text sent to Gemini, skipping")
            return ""
            
        # Debug logging
        print(f"ü§ñ Gemini input: '{text}' | Lang: {source_lang}")
        if context:
            print(f"üìã Context: {context}")
            
        try:
            # Use REST API directly for more reliable connection
            url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent"
            
            headers = {
                'Content-Type': 'application/json',
                'X-goog-api-key': api_key
            }
            
            # Get specialized prompt based on source language and context
            prompt = self._get_translation_prompt(text, source_lang, context, custom_prompt)
            
            data = {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": prompt
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.3,
                    "maxOutputTokens": 200,
                    "topP": 0.9,
                    "topK": 40
                }
            }
            
            response = requests.post(url, headers=headers, json=data, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                if 'candidates' in result and len(result['candidates']) > 0:
                    translated_text = result['candidates'][0]['content']['parts'][0]['text'].strip()
                    
                    # Aggressive cleanup - remove any AI explanations
                    translated_text = self._clean_gemini_response(translated_text)
                    
                    return translated_text if translated_text else text
                else:
                    print("‚ùå No translation candidates in response")
                    return self._translate_with_google(text, source_lang)
            else:
                print(f"‚ùå Gemini API error: {response.status_code} - {response.text}")
                return self._translate_with_google(text, source_lang)
            
        except Exception as e:
            print(f"Gemini translation failed: {e}")
            # Fallback to Google Translate
            return self._translate_with_google(text, source_lang)

    def _get_translation_prompt(self, text, source_lang, context=None, custom_prompt=None):
        """
        Generate enhanced translation prompt with context metadata support
        """
        # If custom prompt provided, use it as instruction, not text to translate
        if custom_prompt and custom_prompt.strip():
            return f"""B·∫°n l√† m·ªôt chuy√™n gia d·ªãch thu·∫≠t manga/comic chuy√™n nghi·ªáp.

INSTRUCTION: {custom_prompt.strip()}

Text c·∫ßn d·ªãch: "{text}"

CH·ªà tr·∫£ v·ªÅ b·∫£n d·ªãch ti·∫øng Vi·ªát c·ªßa text tr√™n, kh√¥ng gi·∫£i th√≠ch g√¨ th√™m."""
        
        # Use default prompt system
        # Parse context metadata
        gender = context.get('gender', 'neutral') if context else 'neutral'
        relationship = context.get('relationship', 'neutral') if context else 'neutral'  
        formality = context.get('formality', 'casual') if context else 'casual'
        bubble_limit = context.get('bubble_limit', None) if context else None
        is_thought = context.get('is_thought', False) if context else False
        is_sfx = context.get('is_sfx', False) if context else False
        scene_context = context.get('scene_context', '') if context else ''
        
        # Build context info
        context_info = []
        if gender != 'neutral':
            context_info.append(f"GENDER: {gender}")
        if relationship != 'neutral':
            context_info.append(f"RELATIONSHIP: {relationship}")
        if formality != 'casual':
            context_info.append(f"FORMALITY: {formality}")
        if bubble_limit:
            context_info.append(f"BUBBLE_LIMIT: {bubble_limit} chars")
        if is_thought:
            context_info.append("TYPE: internal_thought")
        if is_sfx:
            context_info.append("TYPE: sound_effect")
        if scene_context:
            context_info.append(f"SCENE: {scene_context}")
            
        context_str = " | ".join(context_info) if context_info else "No specific context"
        
        # Get language-specific rules
        lang_rules = self._get_language_rules(source_lang)
        
        return f"""D·ªãch "{text}" sang ti·∫øng Vi·ªát.

CONTEXT: {context_str}

{lang_rules}

GLOBAL RULES:
- Ch·ªâ tr·∫£ v·ªÅ chu·ªói b·∫£n d·ªãch, kh√¥ng nh√£n, kh√¥ng ngo·∫∑c k√©p, kh√¥ng gi·∫£i th√≠ch
- M·ªôt d√≤ng v√†o ‚Üí m·ªôt d√≤ng ra (b·∫£o to√†n s·ªë d√≤ng)
- X∆∞ng h√¥ t·ª± ƒë·ªông theo relationship/formality: b·∫°n b√®‚Üí"t√¥i/c·∫≠u"; l·ªãch s·ª±‚Üí"t√¥i/anh(ch·ªã)"; th√¢n m·∫≠t‚Üí"tao/m√†y"
- Kh√¥ng s√°ng t√°c th√™m, d·ªãch trung th·ª±c nh∆∞ng m∆∞·ª£t
- T√™n ri√™ng/k√Ω hi·ªáu: gi·ªØ nguy√™n
- D·∫•u c√¢u Vi·ªát: "‚Ä¶" cho th·ªü d√†i, "‚Äî" cho ng·∫Øt m·∫°nh
- SFX: d·ªãch ng·∫Øn m·∫°nh (vd: "R·∫¶M!", "B·ª§P!")
- Thought: d√πng "‚Ä¶" m·ªÅm, tr√°nh ƒë·∫°i t·ª´ n·∫∑ng
- Bubble fit: ∆∞u ti√™n c√¢u ng·∫Øn t·ª± nhi√™n

CH·ªà TR·∫¢ V·ªÄ B·∫¢N D·ªäCH:"""
    def _get_language_rules(self, source_lang):
        """Get language-specific translation rules"""
        if source_lang == "ja":
            return """JA RULES:
- Keigo‚Üí"·∫°/d·∫°"; th∆∞·ªùng‚Üíb·ªè k√≠nh ng·ªØ
- Senpai/kouhai‚Üí"ti·ªÅn b·ªëi/h·∫≠u b·ªëi" ho·∫∑c gi·ªØ nguy√™n
- „ÇÑ„Å∞„ÅÑ‚Üí"Ch·∫øt ti·ªát!/T·ªá r·ªìi!"; „Åô„Åî„ÅÑ‚Üí"ƒê·ªânh qu√°!"  
- ÊäÄ‚Üí"k·ªπ thu·∫≠t/chi√™u"; ÂøÖÊÆ∫ÊäÄ‚Üí"tuy·ªát k·ªπ"; Â§âË∫´‚Üí"bi·∫øn h√¨nh"
- SFX: „Éê„É≥‚Üí"B√ôNG!"; „Éâ„É≥‚Üí"R·∫¶M!"; „Ç≠„É©„Ç≠„É©‚Üí"l·∫•p l√°nh" """

        elif source_lang == "zh":
            return """ZH RULES:
- ÊÇ®‚Üí"Ng√†i/th∆∞a"; ‰Ω†‚Üí"anh/ch·ªã"; Êúï‚Üí"Tr·∫´m"; Êú¨Áéã‚Üí"B·∫£n v∆∞∆°ng"
- Ê≠¶Âäü‚Üí"v√µ c√¥ng"; ËΩªÂäü‚Üí"khinh c√¥ng"; Ê±üÊπñ‚Üí"giang h·ªì"
- Â¢ÉÁïå‚Üí"c·∫£nh gi·ªõi"; ‰∏πËçØ‚Üí"ƒëan d∆∞·ª£c"; Ê≥ïÂÆù‚Üí"ph√°p b·∫£o"  
- Âìº‚Üí"H·ª´!"; ÂìéÂëÄ‚Üí"√îi tr·ªùi!"; Â§©Âïä‚Üí"Tr·ªùi ∆°i!"
- SFX: ËΩ∞‚Üí"B√ôMM!"; Á†∞‚Üí"ƒê·ª§C!"; ÂíîÂöì‚Üí"K·∫ÆC!" """

        elif source_lang == "ko":
            return """KO RULES:
- Jondaetmal‚Üí"·∫°/d·∫°"; banmal‚Üíb·ªè k√≠nh ng·ªØ
- Ìòï/ÎàÑÎÇò/Ïò§Îπ†/Ïñ∏Îãà‚Üí"anh/ch·ªã"; ÏÑ†Î∞∞‚Üí"ti·ªÅn b·ªëi" 
- ÏïÑÏù¥Í≥†‚Üí"√îi gi·ªùi!"; Ìóê‚Üí"H·∫£?!"; ÏôÄ‚Üí"Wow!"
- Îä•Î†•‚Üí"nƒÉng l·ª±c"; Í∞ÅÏÑ±‚Üí"th·ª©c t·ªânh"; Î†àÎ≤®ÏóÖ‚Üí"l√™n c·∫•p"
- SFX: ÏæÖ‚Üí"C·∫†CH!"; Ïøµ‚Üí"R·∫¶M!"; ÌúòÏùµ‚Üí"V·ª™N!" """

        else:
            return """GENERAL RULES:
- Ph√¢n bi·ªát formal/informal, nam/n·ªØ, gi√†/tr·∫ª
- C·∫£m th√°n: "·ªí!", "Tr·ªùi!", "Ch·∫øt ti·ªát!"
- Hi·ªáu ·ª©ng √¢m thanh: d·ªãch ph√π h·ª£p ti·∫øng Vi·ªát"""

    def _clean_gemini_response(self, response):
        """Enhanced cleaning to remove any AI explanations and return only translation"""
        if not response:
            return ""
            
        # Remove quotes and common prefixes
        cleaned = response.strip().strip('"').strip("'")
        
        # Remove translation labels
        prefixes_to_remove = [
            "B·∫£n d·ªãch:", "D·ªãch:", "Translation:", "Vietnamese:",
            "Ti·∫øng Vi·ªát:", "C√¢u d·ªãch:", "K·∫øt qu·∫£:", "ƒê√°p √°n:",
            "B·∫£n d·ªãch ti·∫øng Vi·ªát:", "Vietnamese translation:",
            "T√¥i s·∫Ω d·ªãch:", "ƒê√¢y l√† b·∫£n d·ªãch:", "C√¢u tr·∫£ l·ªùi:",
        ]
        
        for prefix in prefixes_to_remove:
            if cleaned.lower().startswith(prefix.lower()):
                cleaned = cleaned[len(prefix):].strip()
        
        # Split by common explanation indicators and take first part
        explanation_splits = [
            " (", "[", "Ho·∫∑c", "T√πy", "N·∫øu", "* ", "‚Ä¢ ",
            "- ", "Gi·∫£i th√≠ch:", "L∆∞u √Ω:", "Ch√∫ th√≠ch:",
            "C√≥ th·ªÉ", "Tu·ª≥ theo", "T√πy v√†o"
        ]
        
        for split_pattern in explanation_splits:
            if split_pattern in cleaned:
                parts = cleaned.split(split_pattern)
                if parts[0].strip():
                    cleaned = parts[0].strip()
                    break
        
        # Clean extra whitespace and newlines
        cleaned = " ".join(cleaned.split())
        
        # Final validation - if it contains typical AI response patterns, extract the core translation
        ai_patterns = [
            "c√≥ th·ªÉ d·ªãch", "t√πy ng·ªØ c·∫£nh", "tu·ª≥ theo", "ho·∫∑c l√†",
            "m·ªôt c√°ch kh√°c", "phi√™n b·∫£n kh√°c", "c√°ch kh√°c"
        ]
        
        for pattern in ai_patterns:
            if pattern in cleaned.lower():
                # Try to extract the first clean sentence before the pattern
                sentences = cleaned.split('.')
                if sentences and len(sentences[0]) > 3:
                    cleaned = sentences[0].strip()
                    break
                    
        return cleaned.rstrip('.,!?;:')

    def _preprocess_text(self, text):
        """Enhanced preprocessing for different comic types"""
        # Basic cleaning
        preprocessed_text = text.replace("Ôºé", ".")
        
        # Remove excessive whitespace
        preprocessed_text = " ".join(preprocessed_text.split())
        
        # Clean up common OCR artifacts
        preprocessed_text = preprocessed_text.replace("Ôºà", "(").replace("Ôºâ", ")")
        preprocessed_text = preprocessed_text.replace("ÔºÅ", "!").replace("Ôºü", "?")
        
        return preprocessed_text

    def _delay(self):
        time.sleep(random.randint(3, 5))

    # ============================================================================
    # BATCH TRANSLATION METHODS - New Feature
    # ============================================================================
    
    def batch_translate(self, texts: List[str], method="gemini", source_lang="auto", 
                       context=None, custom_prompt=None) -> List[str]:
        """
        D·ªãch batch texts - t·ªëi ∆∞u cho vi·ªác d·ªãch nhi·ªÅu text c√πng l√∫c
        
        Args:
            texts (List[str]): Danh s√°ch texts c·∫ßn d·ªãch
            method (str): Translation method
            source_lang (str): Source language
            context (dict, optional): Context metadata
            custom_prompt (str, optional): Custom prompt
            
        Returns:
            List[str]: Danh s√°ch texts ƒë√£ d·ªãch
        """
        if not texts:
            return []
        
        # L·ªçc b·ªè text r·ªóng v√† chu·∫©n b·ªã
        clean_texts = []
        text_indices = []  # Track original indices
        
        for i, text in enumerate(texts):
            cleaned = self._preprocess_text(text) if text else ""
            if cleaned.strip():
                clean_texts.append(cleaned)
                text_indices.append(i)
        
        if not clean_texts:
            return [""] * len(texts)
        
        print(f"üîÑ Batch translating {len(clean_texts)} texts using {method}")
        
        # S·ª≠ d·ª•ng API Key Manager n·∫øu c√≥
        if method == "gemini" and self.api_key_manager:
            return self._batch_translate_with_manager(texts, clean_texts, text_indices, 
                                                    source_lang, context, custom_prompt)
        
        # Fallback to individual translation
        results = []
        for text in texts:
            if text and text.strip():
                translated = self.translate(text, method, source_lang, context, custom_prompt)
                results.append(translated)
            else:
                results.append("")
        
        return results
    
    def _batch_translate_with_manager(self, original_texts: List[str], clean_texts: List[str], 
                                    text_indices: List[int], source_lang: str, 
                                    context: dict, custom_prompt: str) -> List[str]:
        """
        Batch translate using API Key Manager v·ªõi rotation
        """
        # T·∫°o batch prompt cho t·∫•t c·∫£ texts
        batch_prompt = self._create_batch_prompt(clean_texts, source_lang, context, custom_prompt)
        
        # Th·ª≠ translate to√†n b·ªô batch v·ªõi API Key Manager
        def translate_func(prompt, api_key):
            return self._translate_batch_with_gemini(prompt, api_key)
        
        batch_result = self.api_key_manager.batch_translate_with_rotation(
            [batch_prompt], translate_func, 'gemini', max_retries=2
        )
        
        if batch_result and batch_result[0]:
            # Parse k·∫øt qu·∫£ batch
            individual_results = self._parse_batch_result(batch_result[0], len(clean_texts))
            
            if len(individual_results) == len(clean_texts):
                # Map k·∫øt qu·∫£ v·ªÅ v·ªã tr√≠ g·ªëc
                final_results = [""] * len(original_texts)
                for i, text_idx in enumerate(text_indices):
                    final_results[text_idx] = individual_results[i]
                
                return final_results
        
        # Fallback: translate t·ª´ng c√°i m·ªôt
        print("‚ö†Ô∏è Batch translation failed, falling back to individual translation")
        return self._fallback_individual_translate(original_texts, source_lang, context, custom_prompt)
    
    def _create_batch_prompt(self, texts: List[str], source_lang: str, 
                           context: dict, custom_prompt: str) -> str:
        """
        T·∫°o prompt cho batch translation
        """
        # Get language rules
        lang_rules = self._get_language_rules(source_lang)
        
        # Build context
        context_info = []
        if context:
            gender = context.get('gender', 'neutral')
            relationship = context.get('relationship', 'neutral')
            formality = context.get('formality', 'casual')
            
            if gender != 'neutral':
                context_info.append(f"GENDER: {gender}")
            if relationship != 'neutral':
                context_info.append(f"RELATIONSHIP: {relationship}")
            if formality != 'casual':
                context_info.append(f"FORMALITY: {formality}")
        
        context_str = " | ".join(context_info) if context_info else "No specific context"
        
        # Custom prompt ho·∫∑c default
        if custom_prompt and custom_prompt.strip():
            instruction = f"""B·∫°n l√† chuy√™n gia d·ªãch manga. H√£y d·ªãch CH√çNH X√ÅC t·ª´ng c√¢u sau sang ti·∫øng Vi·ªát.

INSTRUCTION: {custom_prompt.strip()}

BATCH RULES:
- D·ªãch t·ª´ng d√≤ng m·ªôt c√°ch ri√™ng bi·ªát
- Gi·ªØ nguy√™n th·ª© t·ª± v√† s·ªë l∆∞·ª£ng d√≤ng  
- M·ªói d√≤ng input ‚Üí m·ªôt d√≤ng output t∆∞∆°ng ·ª©ng
- Kh√¥ng th√™m s·ªë th·ª© t·ª±, kh√¥ng gi·∫£i th√≠ch
- CH·ªà tr·∫£ v·ªÅ b·∫£n d·ªãch, kh√¥ng bao g·ªìm instruction"""
        else:
            instruction = f"""D·ªãch CH√çNH X√ÅC t·ª´ng c√¢u sau sang ti·∫øng Vi·ªát.

CONTEXT: {context_str}

{lang_rules}

BATCH RULES:
- D·ªãch t·ª´ng d√≤ng m·ªôt c√°ch ri√™ng bi·ªát
- Gi·ªØ nguy√™n th·ª© t·ª± v√† s·ªë l∆∞·ª£ng d√≤ng
- M·ªói d√≤ng input ‚Üí m·ªôt d√≤ng output t∆∞∆°ng ·ª©ng
- Kh√¥ng th√™m s·ªë th·ª© t·ª±, kh√¥ng gi·∫£i th√≠ch
- T√™n ri√™ng/k√Ω hi·ªáu: gi·ªØ nguy√™n
- Tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng: m·ªói b·∫£n d·ªãch tr√™n 1 d√≤ng, c√°ch nhau b·ªüi \\n"""
        
        # Format texts v·ªõi s·ªë th·ª© t·ª± ƒë·ªÉ d·ªÖ parse
        numbered_texts = []
        for i, text in enumerate(texts, 1):
            numbered_texts.append(f"{i}. {text}")
        
        full_prompt = f"""{instruction}

TEXTS TO TRANSLATE:
{chr(10).join(numbered_texts)}

TRANSLATED RESULTS (one per line):"""
        
        return full_prompt
    
    def _translate_batch_with_gemini(self, prompt: str, api_key: str) -> str:
        """
        Translate batch prompt with specific API key
        """
        try:
            url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent"
            
            headers = {
                'Content-Type': 'application/json',
                'X-goog-api-key': api_key
            }
            
            data = {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": prompt
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.2,
                    "maxOutputTokens": 1000,
                    "topP": 0.8,
                    "topK": 40
                }
            }
            
            response = requests.post(url, headers=headers, json=data, timeout=60)
            
            if response.status_code == 200:
                result = response.json()
                if 'candidates' in result and len(result['candidates']) > 0:
                    return result['candidates'][0]['content']['parts'][0]['text'].strip()
            else:
                print(f"‚ùå Gemini batch API error: {response.status_code}")
                return ""
                
        except Exception as e:
            print(f"‚ùå Batch translation error: {e}")
            return ""
    
    def _parse_batch_result(self, batch_result: str, expected_count: int) -> List[str]:
        """
        Parse k·∫øt qu·∫£ batch translation th√†nh list individual results
        """
        if not batch_result:
            return []
        
        # Clean up response
        cleaned = batch_result.strip()
        
        # Remove any numbering if present
        lines = cleaned.split('\n')
        parsed_results = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # Remove numbering if present (1. 2. etc.)
            import re
            line = re.sub(r'^\d+\.\s*', '', line)
            
            # Remove quotes if present
            line = line.strip('"\'')
            
            if line:
                parsed_results.append(line)
        
        # Ensure we have the right number of results
        while len(parsed_results) < expected_count:
            parsed_results.append("")
        
        return parsed_results[:expected_count]
    
    def _fallback_individual_translate(self, texts: List[str], source_lang: str, 
                                     context: dict, custom_prompt: str) -> List[str]:
        """
        Fallback: translate individual texts khi batch fail
        """
        results = []
        
        # Get API key t·ª´ manager ho·∫∑c fallback
        api_key = None
        if self.api_key_manager:
            api_key = self.api_key_manager.get_api_key('gemini')
        
        if not api_key:
            api_key = self.gemini_api_key
        
        for text in texts:
            if text and text.strip():
                if api_key:
                    translated = self._translate_with_gemini_direct(text, source_lang, context, custom_prompt, api_key)
                else:
                    translated = self._translate_with_google(text, source_lang)
                results.append(translated)
            else:
                results.append("")
        
        return results
    
    def _translate_with_gemini_direct(self, text: str, source_lang: str, context: dict, 
                                    custom_prompt: str, api_key: str) -> str:
        """
        Direct Gemini translation v·ªõi specific API key
        """
        prompt = self._get_translation_prompt(text, source_lang, context, custom_prompt)
        result = self._translate_batch_with_gemini(prompt, api_key)
        
        if result:
            return self._clean_gemini_response(result)
        else:
            return self._translate_with_google(text, source_lang)
    
    def get_api_key_status(self) -> Dict:
        """
        L·∫•y status c·ªßa API keys
        """
        if not self.api_key_manager:
            return {"api_manager": False, "gemini_status": "No manager"}
        
        return {
            "api_manager": True,
            "gemini_status": self.api_key_manager.get_key_status('gemini')
        }
    
    def test_gemini_translation(self, test_text="„Åì„Çì„Å´„Å°„ÅØ", source_lang="ja") -> Dict:
        """
        Ki·ªÉm tra xem d·ªãch thu·∫≠t b·∫±ng Gemini c√≥ ho·∫°t ƒë·ªông ƒë√∫ng kh√¥ng
        
        Args:
            test_text (str): Text ƒë·ªÉ test (m·∫∑c ƒë·ªãnh: "„Åì„Çì„Å´„Å°„ÅØ" - "Xin ch√†o" b·∫±ng ti·∫øng Nh·∫≠t)
            source_lang (str): Ng√¥n ng·ªØ ngu·ªìn (m·∫∑c ƒë·ªãnh: "ja" - ti·∫øng Nh·∫≠t)
            
        Returns:
            Dict: K·∫øt qu·∫£ test bao g·ªìm:
                - success (bool): C√≥ th√†nh c√¥ng kh√¥ng
                - translation (str): K·∫øt qu·∫£ d·ªãch 
                - error (str): L·ªói n·∫øu c√≥
                - api_key_available (bool): API key c√≥ s·∫µn kh√¥ng
                - response_time (float): Th·ªùi gian ph·∫£n h·ªìi (gi√¢y)
                - fallback_used (bool): C√≥ s·ª≠ d·ª•ng fallback kh√¥ng
        """
        import time
        
        print(f"üîç Testing Gemini translation with: '{test_text}' ({source_lang} ‚Üí vi)")
        
        # Ki·ªÉm tra API key
        api_key_available = bool(self.gemini_api_key)
        if self.api_key_manager:
            manager_key = self.api_key_manager.get_api_key('gemini')
            api_key_available = api_key_available or bool(manager_key)
        
        result = {
            "success": False,
            "translation": "",
            "error": "",
            "api_key_available": api_key_available,
            "response_time": 0.0,
            "fallback_used": False,
            "test_input": test_text,
            "source_language": source_lang
        }
        
        if not api_key_available:
            result["error"] = "Kh√¥ng c√≥ API key Gemini ƒë∆∞·ª£c c·∫•u h√¨nh"
            result["success"] = False
            print("‚ùå Gemini API key kh√¥ng c√≥ s·∫µn")
            return result
        
        try:
            start_time = time.time()
            
            # Test v·ªõi context ƒë∆°n gi·∫£n
            test_context = {
                "gender": "neutral",
                "relationship": "friend", 
                "formality": "casual"
            }
            
            # Th·ª≠ d·ªãch b·∫±ng Gemini
            translation = self.translate(
                text=test_text,
                method="gemini",
                source_lang=source_lang,
                context=test_context
            )
            
            end_time = time.time()
            response_time = end_time - start_time
            
            result["response_time"] = round(response_time, 2)
            result["translation"] = translation
            
            # Ki·ªÉm tra xem c√≥ fallback v·ªÅ Google Translate kh√¥ng
            if translation == test_text:
                # N·∫øu k·∫øt qu·∫£ gi·ªëng input, c√≥ th·ªÉ l√† l·ªói
                result["error"] = "K·∫øt qu·∫£ d·ªãch gi·ªëng v·ªõi input, c√≥ th·ªÉ c√≥ l·ªói"
                result["success"] = False
                result["fallback_used"] = True
            elif not translation or translation.strip() == "":
                # N·∫øu k·∫øt qu·∫£ r·ªóng
                result["error"] = "K·∫øt qu·∫£ d·ªãch r·ªóng"
                result["success"] = False
            else:
                # D·ªãch th√†nh c√¥ng
                result["success"] = True
                
                # Ki·ªÉm tra xem c√≥ ph·∫£i l√† k·∫øt qu·∫£ t·ª´ Google Translate kh√¥ng
                # (th·ª≠ d·ªãch c√πng text b·∫±ng Google ƒë·ªÉ so s√°nh)
                try:
                    google_translation = self._translate_with_google(test_text, source_lang)
                    if translation.lower().strip() == google_translation.lower().strip():
                        result["fallback_used"] = True
                        result["error"] = "C√≥ th·ªÉ ƒë√£ fallback v·ªÅ Google Translate"
                    else:
                        result["fallback_used"] = False
                except:
                    # Kh√¥ng th·ªÉ so s√°nh v·ªõi Google, v·∫´n coi l√† th√†nh c√¥ng
                    pass
            
            print(f"‚úÖ Test ho√†n th√†nh trong {response_time:.2f}s")
            print(f"üìù K·∫øt qu·∫£: '{translation}'")
            
            if result["fallback_used"]:
                print("‚ö†Ô∏è C√≥ th·ªÉ ƒë√£ s·ª≠ d·ª•ng fallback")
            
        except Exception as e:
            result["error"] = f"L·ªói khi test: {str(e)}"
            result["success"] = False
            print(f"‚ùå Test th·∫•t b·∫°i: {e}")
        
        return result
    
    def run_comprehensive_gemini_test(self) -> Dict:
        """
        Ch·∫°y b·ªô test to√†n di·ªán cho Gemini translation
        
        Returns:
            Dict: K·∫øt qu·∫£ test chi ti·∫øt cho nhi·ªÅu tr∆∞·ªùng h·ª£p
        """
        print("üß™ B·∫Øt ƒë·∫ßu test to√†n di·ªán cho Gemini translation...")
        
        # C√°c test cases
        test_cases = [
            {"text": "„Åì„Çì„Å´„Å°„ÅØ", "lang": "ja", "name": "Ti·∫øng Nh·∫≠t c∆° b·∫£n"},
            {"text": "‰Ω†Â•Ω", "lang": "zh", "name": "Ti·∫øng Trung c∆° b·∫£n"}, 
            {"text": "ÏïàÎÖïÌïòÏÑ∏Ïöî", "lang": "ko", "name": "Ti·∫øng H√†n c∆° b·∫£n"},
            {"text": "Hello", "lang": "en", "name": "Ti·∫øng Anh c∆° b·∫£n"},
            {"text": "„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô", "lang": "ja", "name": "Ti·∫øng Nh·∫≠t l·ªãch s·ª±"},
            {"text": "ÁßÅ„ÅØÂ≠¶Áîü„Åß„Åô", "lang": "ja", "name": "Ti·∫øng Nh·∫≠t c√¢u d√†i"},
            {"text": "„Éê„É≥ÔºÅ", "lang": "ja", "name": "SFX ti·∫øng Nh·∫≠t"},
            {"text": "„Åô„Åî„ÅÑ...", "lang": "ja", "name": "Thought bubble"},
        ]
        
        results = {
            "overall_success": True,
            "total_tests": len(test_cases),
            "passed_tests": 0,
            "failed_tests": 0,
            "test_results": [],
            "summary": "",
            "recommendations": []
        }
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\nüìã Test {i}/{len(test_cases)}: {test_case['name']}")
            
            # Th√™m context t√πy theo lo·∫°i test
            context = {"formality": "casual"}
            if "SFX" in test_case['name']:
                context["is_sfx"] = True
            elif "thought" in test_case['name'].lower():
                context["is_thought"] = True
            elif "l·ªãch s·ª±" in test_case['name']:
                context["formality"] = "polite"
            
            test_result = self.test_gemini_translation(
                test_text=test_case["text"],
                source_lang=test_case["lang"]
            )
            
            test_result["test_name"] = test_case["name"]
            test_result["test_number"] = i
            
            results["test_results"].append(test_result)
            
            if test_result["success"]:
                results["passed_tests"] += 1
                print(f"‚úÖ {test_case['name']}: PASSED")
            else:
                results["failed_tests"] += 1
                results["overall_success"] = False
                print(f"‚ùå {test_case['name']}: FAILED - {test_result['error']}")
        
        # T·∫°o summary
        success_rate = (results["passed_tests"] / results["total_tests"]) * 100
        results["success_rate"] = round(success_rate, 1)
        
        if results["overall_success"]:
            results["summary"] = f"üéâ T·∫§T C·∫¢ TESTS PASSED! ({results['passed_tests']}/{results['total_tests']})"
        elif success_rate >= 70:
            results["summary"] = f"‚ö†Ô∏è M·ªôt s·ªë tests failed ({results['passed_tests']}/{results['total_tests']} - {success_rate}%)"
        else:
            results["summary"] = f"‚ùå Nhi·ªÅu tests failed ({results['passed_tests']}/{results['total_tests']} - {success_rate}%)"
        
        # Recommendations
        if not results["overall_success"]:
            if not any(r["api_key_available"] for r in results["test_results"]):
                results["recommendations"].append("üîë C·∫ßn c·∫•u h√¨nh Gemini API key")
            
            fallback_count = sum(1 for r in results["test_results"] if r.get("fallback_used"))
            if fallback_count > 0:
                results["recommendations"].append(f"‚ö†Ô∏è {fallback_count} tests s·ª≠ d·ª•ng fallback - ki·ªÉm tra API key ho·∫∑c network")
            
            slow_tests = [r for r in results["test_results"] if r.get("response_time", 0) > 10]
            if slow_tests:
                results["recommendations"].append(f"üêå {len(slow_tests)} tests ch·∫≠m (>10s) - ki·ªÉm tra network")
        
        print(f"\n{results['summary']}")
        for rec in results["recommendations"]:
            print(f"  {rec}")
        
        return results
